How to run DQfD: 

(1) Clone git repo https://github.com/marioyc/minerl2020_dqfd_submission
(2) Copy project_train.py, cached_kmeans.py, and utils.py from our submission repo into main directory
(3) Run python project_train.py or xvfb-run -a python project_train.py (for run without connected monitor) with args (below) 

project_train.py --env MineRLTreechopVectorObf-v0 --outdir result --gpu 0 --noisy-net-sigma 0.5 --replay-buffer-size 300000 --replay-start-size 5000 --target-update-interval 10000 --num-step-return 10 --lr 0.0000625 --frame-stack 4 --frame-skip 4 --gamma 0.99 --batch-accumulator mean --n-pretrain-steps 10000 --n-pretrain-rounds 0 --n-experts 25 --use-noisy-net before-pretraining --only_pretrain 0 --optimizer adam --load 'load_model_directory'

Added args (compared to default): 
--n-pretrain-rounds: number of pertaining rounds (after each round, the agent gets saved)
--n-pretrain-steps: now refers to steps per pretrain round (before: total pretrain steps)
--only_pretrain: only pretraining & evaluation of pretrained agent (no actual training)

